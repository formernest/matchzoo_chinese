{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matchzoo as mz\n",
    "import typing\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def read_data(path):\n",
    "    table = pd.read_csv(path, sep='\\t', header=0, quoting=csv.QUOTE_NONE)\n",
    "    df = pd.DataFrame({\n",
    "        'text_left': table['sentence1'],\n",
    "        'text_right': table['sentence2'],\n",
    "        'label': table['Label']\n",
    "    })\n",
    "    return mz.pack(df)\n",
    "\n",
    "def load_data(\n",
    "    stage: str = 'train',\n",
    "    task: str = 'ranking',\n",
    "    filtered: bool = False,\n",
    "    return_classes: bool = False\n",
    ") -> typing.Union[mz.DataPack, tuple]:\n",
    "    if stage not in ('train', 'dev', 'test'):\n",
    "        raise ValueError(f\"{stage} is not a valid stage.\"\n",
    "                         f\"Must be one of `train`, `dev`, and `test`.\")\n",
    "\n",
    "    data_root = Path(\"/Users/lifang/desktop/project/corpus/LCQMC/data\")\n",
    "    file_path = data_root.joinpath(f'{stage}.txt')\n",
    "    data_pack = read_data(file_path)\n",
    "    if task == 'ranking':\n",
    "        task = mz.tasks.Ranking()\n",
    "    if task == 'classification':\n",
    "        task = mz.tasks.Classification()\n",
    "    if isinstance(task, mz.tasks.Ranking):\n",
    "        return data_pack\n",
    "    elif isinstance(task, mz.tasks.Classification):\n",
    "        data_pack.one_hot_encode_label(task.num_classes, inplace=True)\n",
    "        if return_classes:\n",
    "            return data_pack, [False, True]\n",
    "        else:\n",
    "            return data_pack\n",
    "    else:\n",
    "        raise ValueError(f\"{task} is not a valid task.\"\n",
    "                         f\"Must be one of `Ranking` and `Classification`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  text_left\n",
      "id_left                    \n",
      "L-0        喜欢打篮球的男生喜欢什么样的女生\n",
      "L-1            我手机丢了，我想换个手机\n",
      "L-2                大家觉得她好看吗\n",
      "L-3               求秋色之空漫画全集\n",
      "L-4      晚上睡觉带着耳机听音乐有什么害处吗？\n",
      "               text_right\n",
      "id_right                 \n",
      "R-0       爱打篮球的男生喜欢什么样的女生\n",
      "R-1           我想买个新手机，求推荐\n",
      "R-2            大家觉得跑男好看吗？\n",
      "R-3             求秋色之空全集漫画\n",
      "R-4          孕妇可以戴耳机听音乐吗?\n",
      "  id_left id_right  label\n",
      "0     L-0      R-0      1\n",
      "1     L-1      R-1      1\n",
      "2     L-2      R-2      0\n",
      "3     L-3      R-3      1\n",
      "4     L-4      R-4      0\n",
      "  id_left           text_left id_right       text_right  label\n",
      "0     L-0    喜欢打篮球的男生喜欢什么样的女生      R-0  爱打篮球的男生喜欢什么样的女生      1\n",
      "1     L-1        我手机丢了，我想换个手机      R-1      我想买个新手机，求推荐      1\n",
      "2     L-2            大家觉得她好看吗      R-2       大家觉得跑男好看吗？      0\n",
      "3     L-3           求秋色之空漫画全集      R-3        求秋色之空全集漫画      1\n",
      "4     L-4  晚上睡觉带着耳机听音乐有什么害处吗？      R-4     孕妇可以戴耳机听音乐吗?      0\n"
     ]
    }
   ],
   "source": [
    "task = mz.tasks.Ranking()    \n",
    "train_raw = load_data(stage='train', task=task)  #qa是datasets下新建的包，放置中文数据\n",
    "test_raw = load_data(stage='test', task=task)\n",
    "print(train_raw.left.head())\n",
    "print(train_raw.right.head())\n",
    "print(train_raw.relation.head())\n",
    "print(train_raw.frame().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'matchzoo.embedding.embedding.Embedding'>\n"
     ]
    }
   ],
   "source": [
    "path_vec = \"/Users/lifang/desktop/project/corpus/word2vec/WordVector_60dimensional/wiki.zh.text.vector\"\n",
    "emb = mz.embedding.load_from_file(path_vec, mode='word2vec')\n",
    "# print(emb.shape)\n",
    "print(type(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = mz.models.ArcI\n",
    "# preprocessor_class = mz.preprocessors.chinese_preprocessor.ChinesePreprocessor()\n",
    "# print(preprocessor_class)\n",
    "preprocessor_class = mz.preprocessors.BasicPreprocessor()\n",
    "preprocessor_class._units = [\n",
    "            # mz.preprocessors.units.tokenize.ChineseTokenize(),\n",
    "            mz.preprocessors.units.tokenize.ChineseTokenize(),\n",
    "            # mz.preprocessors.units.lowercase.Lowercase(),\n",
    "            mz.preprocessors.units.punc_removal.PuncRemoval(),\n",
    "        ]\n",
    "\n",
    "model, preprocessor, data_generator_builder, embedding_matrix = mz.auto.prepare(\n",
    "    task=task,\n",
    "    model_class=model_class,\n",
    "    preprocessor=preprocessor_class,\n",
    "    data_pack=train_raw,\n",
    "    embedding=emb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_class                   <class 'matchzoo.models.arci.ArcI'>\n",
      "input_shapes                  [(30,), (30,)]\n",
      "task                          Ranking Task\n",
      "optimizer                     adam\n",
      "with_embedding                True\n",
      "embedding_input_dim           4763\n",
      "embedding_output_dim          60\n",
      "embedding_trainable           True\n",
      "with_multi_layer_perceptron   True\n",
      "mlp_num_units                 128\n",
      "mlp_num_layers                3\n",
      "mlp_num_fan_out               64\n",
      "mlp_activation_func           relu\n",
      "num_blocks                    1\n",
      "left_filters                  [32]\n",
      "left_kernel_sizes             [3]\n",
      "right_filters                 [32]\n",
      "right_kernel_sizes            [3]\n",
      "conv_activation_func          relu\n",
      "left_pool_sizes               [2]\n",
      "right_pool_sizes              [2]\n",
      "padding                       same\n",
      "dropout_rate                  0.0\n",
      "embedding_matrix: \n",
      " <class 'numpy.ndarray'> \n",
      " [[ 0.01798805  0.13321907  0.02238536 ... -0.02820211  0.18273228\n",
      "   0.18436114]\n",
      " [-0.14500743 -0.0936597  -0.12480055 ... -0.07697446 -0.10769513\n",
      "   0.03544196]\n",
      " [ 0.05585458 -0.16892603 -0.16940857 ...  0.13549012  0.05541521\n",
      "   0.06788835]\n",
      " ...\n",
      " [ 0.216191    2.339758   -1.240495   ...  2.818044   -2.081333\n",
      "  -3.105886  ]\n",
      " [-0.558742    0.861456   -0.808444   ... -0.503978   -0.611132\n",
      "  -0.889968  ]\n",
      " [-2.284475    0.237439   -2.59994    ... -1.655816    1.812118\n",
      "  -0.250349  ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.params)   # 展示模型中可调参数\n",
    "model.params['mlp_num_units'] = 3  # 直接调整参数\n",
    "print(\"embedding_matrix: \\n\", type(embedding_matrix), '\\n', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig Text: [3431, 978, 3431, 3431, 1042, 3431, 3431, 3630, 3431, 3431, 628, 3431, 3431, 296, 3431, 3431, 1251, 3431, 3431, 4480, 3431, 3431, 2158, 3431, 3431, 4345, 3431, 3431, 1042, 3431]\n",
      "Transformed Indices: [3431, 978, 3431, 3431, 1042, 3431, 3431, 3630, 3431, 3431, 628, 3431, 3431, 296, 3431, 3431, 1251, 3431, 3431, 4480, 3431, 3431, 2158, 3431, 3431, 4345, 3431, 3431, 1042, 3431]\n",
      "Transformed Indices Meaning:  /男/ / /生/ / /喜/ / /欢/ / /什/ / /么/ / /样/ / /的/ / /女/ / /生/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifang/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1866/1866 [==============================] - 50s 27ms/step - loss: 0.2105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{mean_average_precision(0.0): 0.5073902492830356}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed = preprocessor.transform(train_raw, verbose=0)\n",
    "test_processed = preprocessor.transform(test_raw, verbose=0)\n",
    "\n",
    "vocab_unit = preprocessor.context['vocab_unit']   # 此部分是为了显示处理过程\n",
    "print('Orig Text:', train_processed.left.loc['L-0']['text_left'])\n",
    "sequence = train_processed.left.loc['L-0']['text_left']\n",
    "print('Transformed Indices:', sequence)\n",
    "print('Transformed Indices Meaning:',\n",
    "      '/'.join([vocab_unit.state['index_term'][i] for i in sequence]))\n",
    "\n",
    "train_gen = data_generator_builder.build(train_processed)\n",
    "test_gen = data_generator_builder.build(test_processed)\n",
    "model.fit_generator(train_gen, epochs=1)\n",
    "model.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
